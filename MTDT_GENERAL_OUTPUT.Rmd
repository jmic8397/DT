---
title: "MTDT_Function_ClassifyR"
author: "Andy Wang, Andy Tran & Jamie Mickaill"
date: "01/02/2022"
output: html_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

sessionInfo()

library(MultiAssayExperiment)
library(tidyverse)
library(magrittr)
library(rms)
library(Hmisc)
library(skimr)
library(knitr)
library(hardhat)
library(caret)
library(grid)
library(gridExtra)
library(tictoc)
library(ClassifyR)
library(data.tree)
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(knitr)
library(png)
library(magrittr)
library(DT)
library(e1071)
library(randomForest)

tictoc::tic()

dataDirMelanoma = "./melanomaAssaysNorm.RData"
dataDirCovid = "./COMBAT_COVID_MAE_20220703.RDATA"
dataDirBioHeart = "./MultiAssayExperiment_PLM_20210519_ageCorrected"

WDir = "C:/Users/jamie/Desktop/UniY3S1/DataScience/DENR3901/Prereadings/MTDT2021Version/NewDATA"
WDirR = "C:/Users/jamie/Desktop/UniY3S1/DataScience/DENR3901/Prereadings/MTDT2021Version"

setwd(WDir)
load(dataDirCovid)
original_naming = c("COVID_HCW_MILD", "COVID_HCW_SEVERE", "COVID_HCW_CONV", "COVID_HCW_ASYMPTOMATIC", "HV", "Sepsis", "COVID_MILD", "COVID_SEV", "COVID_CRIT", "Flu")
new_naming = c("Good", "Bad", NA, "Good", NA, NA, "Good", "Bad", "Bad", NA)
COVID_MAE$outcome_bin <- factor(plyr::mapvalues(COVID_MAE$Source, original_naming, new_naming))
setwd(WDirR)

source("./MTDT-0-fxn-SSER.R")
source("./MTDT-0-fxn-GeneralMTDT.R")
source("./MTDT-0-fxn-MTblock.R")
source("./MTDT-0-fxn-others.R")
source("./MTDT-0-fxn-MTDT.R")
# source("./MTDT-1-datachecking.R")




```

# Multi Tier Decision Tree for Clinical Diagnostics

This program aims to use a sequential, machine learning approach to build a forest of multi-level clinical 
diagnostic trees with multi-omics data. This will allow for comparison of the cost and accuracy of different sequences of predictive models. With this information, we hope to enable better informed decisions of diagnostic processes.

(Andy Wang) The idea here is that we would predict patients' outcome with the input models in sequence/tiers. Once a prediction has been made for a particular patient/sample with an input model, we would determine if the error rate for that patient using that particular model is satisfactory by setting a pre-determined error rate cutoff. If the patient/sample specific accuracy rate (SSER) is too high, this particular patient/sample would progress to the next tier model, until either the SSER is satisfactory, or we determined the patient/sample could not be satisfactorily classified with the input models we have.  

At each node of the tree, a machine learning model is used to establish the sample specific accuracy of health outcome predictions for a single layer of the multi-omics data (e.g. how accurate is the prediction for a single individual based on their histology data?). If the prediction can not be made with sufficient accuracy, the individual will progress to the next level where an alternative model and layer of the omics data will be used. Currently each layer is analysed seperately, such that we have analysis of multiple single-omics datasets (ensemble learning to be implemented ?) 

(Andy Wang)
 There are differences in terms of how these predictors variables could be obtained, how invasive they could be acquired, and how much they cost. The goal here is to find an optimal testing sequence with the different input models that we have, balancing it with the tier model error rates (TSER), the difficulty and differences in their unit cost.  




```{r}
  
#User Inputs
  
###############################################################################

#Choose the MultiAssayExperiment Object for performing classification   
MultiAssayExperiment = COVID_MAE


  
#Properties for weighting 
#(E.g. # of individuals retained or total cost of all tests performed at a given tier)
properties = c("TSA.retained", "Cost.Total")

#To be updated: 
#Currently weighting function is incorrect: (scaled(P1) * W1) + (scaled(P1) * W2) + (scaled(PN) * WN) 

#Weights for properties
#(E.g. evaluation of best tier defined by relative error * -0.5 + relative cost * -0.5 )
weights = c(0.5,-0.5)

#List of tier names
#For melanoma example: longRNA has too many features, we just want a single iTRAQ****
tierList = c( "RNAseq"  ,    "Luminex"   , "CITEseq") 

#Sample specific error cutoffs 
#(E.g. x | if the sample specific error of cross validated prediction is > x, the sample will 'progress' to the next tier. Lower cutoff = higher retention generally)
# ssercutoffList= list(c(0.4, 0.4, 0.4),c(0.6, 0.6, 0.6)) # -> For multi-threshold analysis
ssercutoffLists= list(c(0.2, 0.2, 0.2))

#Tier costs (e.g. price of performing test for an individual), Clinical also last index
tierUnitCosts = c(100, 500, 1000)

#Which tier to fix as first in Tree? (If any)
# e.g. fixedTier = "Clinical"
# fixedTier = "clinical"
fixedTier = "RNAseq"

#Choose whether CV needed?
#runtest() or runtests()? 
runtestorruntests = "runtests"

#name of classifier/classes column in dataset
classes = "outcome_bin"

#Performance type (e.g. Sample Error) 
performanceType = "Sample Error"


##Cross validation parameters (could create a list for each experiment)
crossValParams = CrossValParams(
    samplesSplits = "Permute k-Fold",
    permutations = 5,
    percentTest = 25,
    folds = 5,
    leave = 2,
    tuneMode = "none",
    parallelParams = bpparam()
)



##Data transformation parameters
# transformParams = TransformParams(transform, characteristics = DataFrame(), intermediate = character(0), ...)
transformParamsList = c(NULL,NULL,NULL)



##Feature selection parameters
# selectParams = SelectParams(featureSelection, characteristics = DataFrame(), minPresence = 1, intermediate = character(0), subsetToSelections = TRUE, tuneParams = list(nFeatures = seq(10, 100, 10), performanceType = "Balanced Error"), ...)
selectParamsList = c(SelectParams(),SelectParams(),SelectParams())


##Training Parameters -> Insert classifier here
# To do: make this easier for the user by creating a funciton which will return the selectParamsList based on a simple classifier name, e.g. "SVM" will return SelectParams(SVMtrainInterface, kernel = "linear")?
#TrainParams = TrainParams(classifier, characteristics = DataFrame(), intermediate = character(0), getFeatures = NULL, ...)
trainParamsList = c(TrainParams(SVMtrainInterface, kernel = "linear", tuneParams = list(cost = c(0.01, 0.1, 1, 10))),TrainParams(randomForestTrainInterface),TrainParams())

##Prediction Parameters -> Insert classifier here
# PredictParams(predictor, characteristics = DataFrame(), intermediate = character(0), ...)
predictParamsList = c(PredictParams(SVMpredictInterface),PredictParams(randomForestPredictInterface),PredictParams())

##Modelling params List
modellingParams = list()

for(model in 1:length(tierList)){
  currModellingParams = ModellingParams(
    balancing = "none",
    transformParams  = NULL,
    selectParams = selectParamsList[[model]],
    trainParams = trainParamsList[[model]],
    predictParams = predictParamsList[[model]],
    doImportance = FALSE
)
  
  modellingParams = c(modellingParams,currModellingParams)
}




#describing the characteristics of the classification used
# characteristics = S4Vectors::DataFrame()
#to do: make a list and test out some non-null values
characteristics = NULL

seed=1
verbose=3
  
###############################################################################

```

## Main Code

 
```{r, echo=FALSE}

#Call general function with all inputs needed for ClassifyR

source("./MTDT-0-fxn-SSER.R")
source("./MTDT-0-fxn-GeneralMTDT.R")
source("./MTDT-0-fxn-MTblock.R")
source("./MTDT-0-fxn-others.R")
source("./MTDT-0-fxn-MTDT.R")
# source("./MTDT-1-datachecking.R")

#filter NA's for class
classColumn = grep(classes, colnames(colData(MultiAssayExperiment)))
retainList = !is.na(colData(MultiAssayExperiment)[classColumn])
MultiAssayExperiment = MultiAssayExperiment[,retainList & !is.na(retainList),]

#Subset specified experiments from tierList 
MultiAssayExperiment = MultiAssayExperiment[,,tierList[tierList != "clinical"]]

#Subset complete cases only for all assays
#If this is removed, 'not-processed' samples will exist at some tiers for NA's
MultiAssayExperiment = MultiAssayExperiment[,complete.cases(MultiAssayExperiment),]

MTDTsummaries = list()
MTDTresultsList = list()

for(cutoff in 1:length(ssercutoffLists)){
  
  MTDTresults = GeneralMTDT(MultiAssayExperiment,
                        tierList,fixedTier,ssercutoffLists[[cutoff]],
                        tierUnitCosts = tierUnitCosts , performanceType = performanceType,
                       runtestorruntests = runtestorruntests ,classes, crossValParams = crossValParams, modellingParams = modellingParams, characteristics = characteristics,  seed, verbose)
  
  MTDTresultsList = append(MTDTresultsList, list(MTDTresults))
  
  costSummary = MTDT.ClassifyR.cost.summary(MTDTresults, tierUnitCosts)
  
  MTDTsummaries = append(MTDTsummaries,list(costSummary))
  
}



```

## Plots

Updates

* Accuracy instead of Error
* Changes axis on bubble plot (from y = retention to y = cost)
* Concentric bubbles to represent tier retention proportions
* Table -> remove proportion retained but keep total accuracy?

New plots

* Tree plot with numbers of samples progressed represented on edge lines



```{r   , echo=FALSE}

#Bubble plots

for(results in 1:length(MTDTsummaries)){
  
  MTDTsummary = MTDTsummaries[[results]]
  MTDTresults = MTDTresultsList[[results]]

  cap1 = paste("Sequence Accuracy Plot ",results,", Cutoff:", MTDTresults$ssercutoffList[[1]], sep = " ", collapse = NULL)

  tierSequence = MTDTsummary$TSER.summary$Tier.Sequence

  # Scatterplot with total model error
  theme_set(theme_bw())  # pre-set the bw theme.
  g <- ggplot(MTDTsummary$TSER.summary, aes((MTDTsummary$TSER.summary$TSA.retained * MTDTsummary$TSER.summary$N.retained )/MTDTsummary$TSER.summary$N.Total , MTDTsummary$TSER.summary$Cost.Total)) + 
    labs(subtitle="Accuracy and Cost", title=cap1, x = "Total Sequence Accuracy", y = "Total Cost")
  
  nperms = dim(MTDTresults$myperms)[1]

        
#for each permutation we want to add concentric circles representing proportions of retention

  for(nperm in 1:nperms){
    
    
    #Print Tree info in text format
    treeRoot = MTDTsummary$Plots.Tree[[nperm]]
    print("\n")
    print(MTDTsummary$TSER.summary$Tier.Sequence[nperm])
    print("\n")
    print(treeRoot,"counter","tierOrder")
    df = ToDataFrameTree(treeRoot,"counter", "tierOrder")
    df = df %>% filter(grepl('^.*Retained',levelName))
    df = df %>% mutate(counterSum = cumsum(counter))

    #for each level of the permutation make a circle representing the relative proportion of the level (e.g. retained for each experiment)
    
    for(i in 1:length(df$levelName)){
      
      MTDTsummary$TSER.summary$TSA.retained
      print(df$counterSum[i]/df$counterSum[length(df$counterSum)])
      
        g = g + geom_point(aes_(x=((MTDTsummary$TSER.summary$TSA.retained[nperm] * MTDTsummary$TSER.summary$N.retained[nperm] ) /MTDTsummary$TSER.summary$N.retained[nperm] ), y= MTDTsummary$TSER.summary$Cost.Total[nperm], size = (df$counterSum[i]/df$counterSum[length(df$counterSum)]), colour = df$tierOrder[i] ),alpha = 0.05, show.legend=FALSE) 
    }
  }

totalTierAccuracies = (MTDTsummary$TSER.summary$TSA.retained * MTDTsummary$TSER.summary$N.retained )/MTDTsummary$TSER.summary$N.retained 

#increasing range of axis to allow proper view of circles
g = g+ geom_text(label = MTDTsummary$TSER.summary$Tier.Sequence, hjust=0, vjust=0)
 g = g + scale_size_continuous(range=c(10,30)) +  coord_cartesian(xlim= c(0.9*min(totalTierAccuracies),1.1*max(totalTierAccuracies)), ylim=c(0.9*min(MTDTsummary$TSER.summary$Cost.Total),1.1*max(MTDTsummary$TSER.summary$Cost.Total)))
print(g)

}

```


```{r, echo=FALSE}

#Table
TSUM = MTDTsummaries[[1]]$TSER.summary
nperms = dim(MTDTresults$myperms)[1]

#combine threshold tables
if(length(MTDTsummaries) > 1){
  
  for(results in 2:length(MTDTsummaries)){
      #Merge threshold tables
      TSUM = rbind(TSUM,MTDTsummaries[[results]]$TSER.summary)
    }
  }

##########################
#weight function
#adds a column for each feature which holds the features individual contribution to the total

#Scales col vals and multiplies by weight
getWeights <- function(data,properties, weights){

  originalLength = length(data)
  sum = 0
  
  #for each property and weight, create a new column corresponding to its contribution to the total weight
  for(i in 1:length(properties)){
    colname = paste0(properties[i],".weight")
    
    data[colname] <- ((scale(data[properties[i]])) * weights[i]) 
  }
  
  #sum up all new cols
  data = data %>% mutate(Weight = rowSums(.[(originalLength+1):length(data)]))
  
  
  return(data)

}

TSUM = getWeights(TSUM,properties,weights)

########################
  
tab = TSUM %>% select(Tier.Sequence, TSA.retained, N.Total, Threshold,Cost.byTier,Cost.Total, Weight) %>%
DT::datatable(option=list( columnDefs=list(list(className="dt-center", targets=list(1,6))),
  pageLength=20) ) %>%  DT::formatRound(columns=c(2, 3, 6), digits=2)
  
print(tab)
tab
```

```{r results='asis'  , echo=FALSE}

for(results in 1:length(MTDTsummaries)){
  
  MTDTsummary = MTDTsummaries[[results]]
  MTDTresults = MTDTresultsList[[results]]
  
  nperms = dim(MTDTresults$myperms)[1]
  
  for (nperm in 1:nperms){
    
    #Print tree plot
    treeRoot = MTDTsummary$Plots.Tree[[nperm]]
    ############################
      
    n = nrow(colData(MultiAssayExperiment))

    #strat plot of all tiers
    p1 = MTDTsummary$Plots.strat.prop[[nperm]] +
        theme(plot.title=element_text(face="bold"))
    #Tier specific error box plots
    p2 = MTDTsummary$Plots.TSERcutoff[[nperm]][[1]]
    p3 = MTDTsummary$Plots.TSERcutoff[[nperm]][[2]] + ylab("")
    p4 = MTDTsummary$Plots.TSERcutoff[[nperm]][[3]] + ylab("")
    #overall error
    p5 = MTDTsummary$Plots.TSER[[nperm]] + 
        ggtitle("Overall") + ylab("") +
        theme(plot.title=element_text(hjust=0.5, face="bold"))
      
      
      
    #MTDTsummary$Plots.Tree[[nperm]]
      
    gridExtra::grid.arrange(
      grobs = list( p1, p2, p3,p4,  p5),
      layout_matrix = rbind(c(1,1,1,1),
                            c(1,1,1,1),
                            c(2,3,4,5),
                            c(2,3,4,5),
                            c(2,3,4,5))
    )
      
      
    #Tree Graph
    ############################################
    
     GetEdgeLabel <- function(node) {
    if (!node$isRoot ) {
      val = round((node$counter/n)*100,3)
      label = paste0( (val),  "% (", node$counter, ")")
    } else {
      label = node$name
    }
    return (label)
      
    }
    
  
    GetFillColour <- function(node){
      if(!is.null(node$tier)){
            name = node$tier
  
      name = name %>% charToRaw %>% as.numeric %>%paste(collapse = '')
      
      return(paste0('#',((strtoi(name)*255)%%100),'FF89'))}
      else{
        return("LightBlue")
      }
  
  
    }
  
    SetGraphStyle(treeRoot, rankdir = "LR")
    SetEdgeStyle(treeRoot, fontname = 'helvetica', label = GetEdgeLabel)
    # SetNodeStyle(treeRoot, style="filled", shape = "box", fillcolor = GetFillColour, fontname = 'helvetica')
    SetNodeStyle(treeRoot, style="filled", shape = "box", fillcolor = "LightBlue", fontname = 'helvetica')

    Graph = ToDiagrammeRGraph(treeRoot)
    graphname = paste0("graph",nperm, ".png")
    export_graph(Graph, file_name = graphname, file_type = "png")
    graphpath = paste0(getwd(), "/",graphname)
    cat("![](",graphname,")")

      }

  }



```

